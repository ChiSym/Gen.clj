<!DOCTYPE html>
<html><head><meta charset="UTF-8"><meta content="width=device-width, initial-scale=1" name="viewport"><meta property="og:description"><meta property="og:title"><meta content="article:clerk" property="og:type"><meta content="summary_large_image" name="twitter:card"><script src="https://cdn.tailwindcss.com?plugins=typography" type="text/javascript"></script><script>tailwind.config = {
  darkMode: "class",
  content: ["./tw/viewer.js", "./tw/**/*.edn"],
  safelist: ['dark'],
  theme: {
    extend: {},
    fontFamily: {
      sans: ["Fira Sans", "-apple-system", "BlinkMacSystemFont", "sans-serif"],
      serif: ["PT Serif", "serif"],
      mono: ["Fira Mono", "monospace"]
    }
  },
  variants: {
    extend: {},
  },
  plugins: [],
}
</script><style type="text/tailwindcss">@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  html {
    font-size: 18px;
  }
  @media (max-width: 600px) {
    html {
      font-size: 16px;
    }
  }
  .font-condensed { font-family: "Fira Sans Condensed", sans-serif; }
  .font-inter     { font-family: "Inter", sans-serif; }
  body {
    @apply font-serif antialiased text-gray-900 sm:overscroll-y-none;
  }
  code, .code {
    @apply font-mono text-sm text-gray-900 bg-slate-50 px-0.5 py-px rounded dark:bg-gray-800;
  }
  code::before, code::after { @apply content-none !important; }
  h1, h3, h4, h5, h6 {
    @apply font-condensed font-bold mt-8 first:mt-0;
  }
  h2 {
    /*We cannot collapse margins due to nesting but we want to*/
    /*keep the h2’s large margin visible*/
    @apply font-condensed font-bold mt-8 first:mt-2;
  }
  h1 { @apply text-4xl; }
  h2 { @apply text-3xl; }
  h3 { @apply text-2xl; }

  @media print {
      h1 { @apply text-2xl !important; }
      h2 { @apply text-xl !important; }
      h3 { @apply text-lg !important; }
  }

  button { @apply focus:outline-none; }
  strong { @apply font-bold; }
  em     { @apply italic; }
  pre    { @apply m-0 font-mono; }
  table img { @apply inline-block; }
}

/* Compatibility */
/* --------------------------------------------------------------- */
/* TODO: Verify which colors are in use and replace with Tailwind
   colors accordingly. Move Nj-specific styles out of here. */

:root {
  --teal-color: #31afd0;
  --dark-teal-color: #095960;
  --near-black-color: #2e2e2c;
  --red-color: #d64242;
  --dark-blue-color: #1f2937;
  --dark-blue-60-color: rgba(28, 42, 56, 0.6);
  --gray-panel-color: rgba(239, 241, 245, 1.000);
  --brand-color: var(--dark-blue-color);
  --link-color: #5046e4;
  --command-bar-selected-color: var(--teal-color);
}

.serif      { @apply font-serif; }
.sans-serif { @apply font-sans; }
.monospace  { @apply font-mono; }
.inter      { @apply font-inter; }

.border-color-teal { border-color: var(--dark-teal-color); }
.teal { color: var(--teal-color); }
.bg-dark-blue { background: var(--dark-blue-color); }
.bg-dark-blue-60 { background: rgba(28, 42, 56, 0.6); }
.bg-gray-panel { background: var(--gray-panel-color); }
.text-dark-blue  { color: var(--dark-blue-color); }
.text-dark-blue-60 { color: var(--dark-blue-60-color); }
.border-dark-blue-30 { border-color: rgba(28, 42, 56, 0.6); }
.text-brand { color: var(--dark-blue-color); }
.bg-brand { background: var(--dark-blue-color); }
.text-selected { color: white; }
.red { color: var(--red-color); }

/* Disclose Button */
/* --------------------------------------------------------------- */

.disclose {
  @apply content-none border-solid cursor-pointer inline-block relative mr-[3px] top-[-2px] transition-all;
  border-color: var(--near-black-color) transparent;
  border-width: 6px 4px 0;
}
.disclose:hover {
  border-color: var(--near-black-color) transparent;
}
.dark .disclose,
.dark .disclose:hover {
  border-color: white transparent;
}
.disclose.collapsed {
  @apply rotate-[-90deg];
}

/* Layout */
/* --------------------------------------------------------------- */

.page {
  @apply max-w-5xl mx-auto px-12 box-border flex-shrink-0;
}
.max-w-prose { @apply max-w-[46rem] !important; }
.max-w-wide  { @apply max-w-3xl !important; }

/* List Styles */
/* --------------------------------------------------------------- */

.task-list-item + .task-list-item,
.markdown-viewer ul ul {
  @apply mt-1 mb-0;
}

/* compact TOC */
.markdown-viewer .toc ul {
  list-style: none;
  @apply my-1;
}

/* Code Viewer */
/* --------------------------------------------------------------- */

.code-viewer {
  @apply font-mono bg-slate-100 rounded-sm text-sm overflow-x-auto dark:bg-gray-800;
}
.code-listing  {
    @apply -ml-8 -mr-8 relative !important;
}
.code-viewer .cm-content {
  @apply py-4 px-8;
}
@media (min-width: 960px){
    .notebook-viewer .code-viewer .cm-content {
        @apply pl-12;
    }
    .notebook-viewer .code-listing {
        width: 48rem !important;
        @apply -ml-12 mr-0 !important;
    }
}
/* Don’t show focus outline when double-clicking cell in Safari */
.cm-scroller { @apply focus:outline-none; }

/* Syntax Highlighting */
/* --------------------------------------------------------------- */

.inspected-value { @apply text-xs font-mono leading-[1.25rem]; }
.cmt-strong, .cmt-heading { @apply font-bold; }
.cmt-italic, .cmt-emphasis { @apply italic; }
.cmt-strikethrough { @apply line-through; }
.cmt-link { @apply underline; }
.untyped-value { @apply whitespace-nowrap; }

.cm-editor, .cmt-default, .result-viewer {
  @apply text-slate-800 dark:text-slate-300;
}
.cmt-keyword {
  @apply text-purple-800 dark:text-pink-400;
}
.cmt-atom, .cmt-bool, .cmt-url, .cmt-contentSeparator, .cmt-labelName {
  @apply text-blue-900 dark:text-blue-300;
}
.cmt-inserted, .cmt-literal {
  @apply text-emerald-700 dark:text-emerald-200;
}
.cmt-string, .cmt-deleted {
  @apply text-rose-700 dark:text-sky-300;
}
.cmt-italic.cmt-string {
  @apply dark:text-sky-200;
}
.cmt-regexp, .cmt-escape {
  @apply text-orange-500 dark:text-orange-300;
}
.cmt-variableName {
  @apply text-blue-800 dark:text-sky-300;
}
.cmt-typeName, .cmt-namespace {
  @apply text-emerald-600 dark:text-emerald-300;
}
.cmt-className {
  @apply text-teal-600 dark:text-teal-200;
}
.cmt-macroName {
  @apply text-teal-700 dark:text-teal-200;
}
.cmt-propertyName {
  @apply text-blue-700 dark:text-blue-200;
}
.cmt-comment {
  @apply text-slate-500 dark:text-slate-400;
}
.cmt-meta {
  @apply text-slate-600 dark:text-slate-400;
}
.cmt-invalid {
  @apply text-red-500 dark:text-red-300;
}

.result-data {
  @apply font-mono text-sm overflow-x-auto whitespace-nowrap leading-normal;
}
.result-data::-webkit-scrollbar, .path-nav::-webkit-scrollbar {
  @apply h-0;
}
.result-data-collapsed {
  @apply whitespace-nowrap;
}
.result-data-field {
  @apply ml-4 whitespace-nowrap;
}
.result-data-field-link{
  @apply ml-4 whitespace-nowrap cursor-pointer;
}
.result-data-field-link:hover {
  @apply text-black bg-black/5;
}
.result-text-empty {
  color: rgba(0,0,0,.3);
}
.browsify-button:hover {
  box-shadow: -2px 0 0 2px #edf2f7;
}

/* Prose */
/* --------------------------------------------------------------- */

.notebook-viewer,
.markdown-viewer {
  @apply prose
    dark:prose-invert
    prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline
    dark:prose-a:text-blue-300
    prose-p:mt-4 prose-p:leading-snug
    prose-ol:mt-4 prose-ol:mb-6 prose-ol:leading-snug
    prose-ul:mt-4 prose-ul:mb-6 prose-ul:leading-snug
    prose-blockquote:mt-4 prose-blockquote:leading-snug
    prose-hr:mt-6 prose-hr:border-t-2 prose-hr:border-solid prose-hr:border-slate-200
    prose-figure:mt-4
    prose-figcaption:mt-2 prose-figcaption:text-xs
    prose-headings:mb-4
    prose-table:mt-0
    prose-th:mb-0
    prose-img:my-0
    prose-code:font-medium prose-code:bg-slate-100
    max-w-none;
}
.markdown-viewer blockquote p:first-of-type:before,
.markdown-viewer blockquote p:last-of-type:after {
  @apply content-none;
}
.markdown-node-viewer.result-viewer.fragment-item {
    @apply mb-0 !important;
}

/* Images */
/* --------------------------------------------------------------- */


/* Todo Lists */
/* --------------------------------------------------------------- */

.contains-task-list {
  @apply pl-6 list-none;
}
.contains-task-list input[type="checkbox"] {
  @apply appearance-none h-4 w-4 rounded border border-slate-200 relative mr-[0.3rem] ml-[-1.5rem] top-[0.15rem];
}
.contains-task-list input[type="checkbox"]:checked {
  @apply border-indigo-600 bg-indigo-600 bg-no-repeat bg-contain;
  background-image: url("data:image/svg+xml,%3csvg viewBox='0 0 16 16' fill='white' xmlns='http://www.w3.org/2000/svg'%3e%3cpath d='M12.207 4.793a1 1 0 010 1.414l-5 5a1 1 0 01-1.414 0l-2-2a1 1 0 011.414-1.414L6.5 9.086l4.293-4.293a1 1 0 011.414 0z'/%3e%3c/svg%3e");
}

/* Markdown TOC */
/* --------------------------------------------------------------- */

.markdown-viewer .toc      { @apply mt-4; }
.markdown-viewer h1 + .toc { @apply mt-8; }

.markdown-viewer .toc h1,
.markdown-viewer .toc h2,
.markdown-viewer .toc h3,
.markdown-viewer .toc h4,
.markdown-viewer .toc h5,
.markdown-viewer .toc h6 {
  @apply text-base text-indigo-600 font-sans my-0;
}
.markdown-viewer .toc a {
  @apply text-indigo-600 font-normal no-underline hover:underline;
}
.markdown-viewer .toc li    { @apply m-0; }
.markdown-viewer .toc ul ul { @apply pl-4; }

/* Notebook Spacing */
/* --------------------------------------------------------------- */

.markdown-viewer *:first-child:not(.code-viewer):not(li):not(h2):not(.sidenote) { @apply mt-0; }
/*.viewer + .viewer { @apply mt-6; }*/
.viewer + .result-viewer { @apply mt-0; }
.code-viewer + .result-viewer { @apply mt-3; }
.markdown-viewer + .markdown-viewer { @apply mt-0; }

/* Sidenotes */
/* --------------------------------------------------------------- */

.sidenote-ref {
  @apply top-[-0.5em] w-auto h-auto inline border-0 bg-transparent m-0 pointer-events-none;
}
.sidenote {
  @apply block font-sans text-xs mt-4 bg-slate-100 dark:bg-slate-800 p-4;
  font-style: normal;
  font-weight: normal;
}
.sidenote-container {
  @apply mb-4;
}
@media (min-width: 860px) {
  .sidenote sup { @apply inline; }
  .sidenote-column {
    @apply w-[165px] absolute right-0 top-0 -mr-[205px];
  }
  .sidenote {
    @apply bg-transparent dark:bg-transparent p-0;
  }
  .sidenote:first-child {
    @apply mt-1;
  }
  .sidenotes-layout .markdown-viewer {
    @apply pr-[241px];
  }
  .sidenote-container {
    @apply relative mb-0;
  }
  .sidenotes-layout h1 {
    @apply w-[756px] !important;
  }
}
.code-viewer + .viewer:not(.code-viewer):not(.code-viewer-folded),
.code-viewer-folded + .viewer:not(.code-viewer):not(.code-viewer-folded),
.result-viewer:not(.markdown-node-viewer) + .result-viewer {
  @apply mt-2;
}
.code-viewer + .code-viewer-folded {
  @apply mt-4;
}
.result-viewer {
  @apply leading-tight mb-6;
}
.code-viewer.fragment-item.result-viewer {
  @apply mb-0 !important;
}
.result-viewer figure {
  @apply mt-0 !important;
}
@media (min-width: 768px) {
  .devcard-desc > div {
    @apply max-w-full m-0;
  }
}

/* Command Palette */
/* --------------------------------------------------------------- */

.nj-commands-input {
  @apply bg-transparent text-white;
}
.nj-context-menu-item:hover:not([disabled]) {
  @apply cursor-pointer;
  background-color: rgba(255,255,255,.14);
}

/* Devdocs */
/* --------------------------------------------------------------- */

.logo, .logo-white {
  @apply block indent-[-999em];
  background: url(/images/nextjournal-logo.svg) center center no-repeat;
}
.devdocs-body {
  @apply font-inter;
}

/* Workarounds */
/* --------------------------------------------------------------- */

/* Fixes vega viewer resizing into infinity */
.vega-embed .chart-wrapper { @apply h-auto !important; }
/* fixes fraction separators being overridden by tw’s border-color */
.katex * { @apply border-black; }

@media print {
    .dark-mode-toggle,
    .toc-toggle { @apply hidden; }
    .notebook-viewer { @apply pt-0; font-size: 12pt !important; margin-left: 0 !important; }
    .code-viewer .cm-content,
    .viewer-code .cm-content { @apply whitespace-pre-wrap !important; overflow: none; }
    .code-viewer .cm-line { font-size: 12pt !important; }
    html * { page-break-inside: avoid !important; }
    .toc-panel { @apply hidden; }
}
</style><script src="https://cas.clerk.garden/tree/8VxCcd2nQqrhPLVttyyM5Rnv8qMYcjeSEjgJnhZTvCgVhmgsNWWeusxmVkfX9ajrXmFqQEdVmtdHSoCdHLG2XTsXXB/.clerk/shadow-cljs/main.js" type="module"></script><link href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://fonts.bunny.net" rel="preconnect"><link href="https://fonts.bunny.net/css?family=fira-mono:400,700%7Cfira-sans:400,400i,500,500i,700,700i%7Cfira-sans-condensed:700,700i%7Cpt-serif:400,400i,700,700i" rel="stylesheet" type="text/css"></head><body class="dark:bg-gray-900"><div id="clerk"></div><script type="module">let viewer = nextjournal.clerk.sci_env
let state = "{:bundle? false, :path->doc {\"examples/intro_to_modeling/edit.clj\" {:path [], :nextjournal/value {:toc [], :sidenotes? false, :toc-visibility false, :atom-var-name->state #viewer-eval (nextjournal.clerk.render/intern-atoms! {}), :ns #viewer-eval (ns intro-to-modeling.edit), :file \"examples/intro_to_modeling/edit.clj\", :scope intro-to-modeling.edit, :bundle? false, :header {:path [], :nextjournal/value [:div.viewer.w-full.max-w-prose.px-8.not-prose.mt-3 [:div.mb-8.text-xs.sans-serif.text-slate-400 nil [:<> [:a.font-medium.border-b.border-dotted.border-slate-300.hover:text-indigo-500.hover:border-indigo-500.dark:border-slate-500.dark:hover:text-white.dark:hover:border-white.transition {:href \"./../../\"} \"Index\"] [:span.mx-2 \"•\"]] [:span \"Generated with \" [:a.font-medium.border-b.border-dotted.border-slate-300.hover:text-indigo-500.hover:border-indigo-500.dark:border-slate-500.dark:hover:text-white.dark:hover:border-white.transition {:href \"https://clerk.vision\"} \"Clerk\"] \" from \" [:a.font-medium.border-b.border-dotted.border-slate-300.hover:text-indigo-500.hover:border-indigo-500.dark:border-slate-500.dark:hover:text-white.dark:hover:border-white.transition {:href \"https://github.com/InferenceQL/gen.clj/blob/4534e1c5d173e7b58f08990ac02374f682f26e01/examples/intro_to_modeling/edit.clj\"} \"examples/intro_to_modeling/edit.clj\" [:<> \"@\" [:span.tabular-nums \"4534e1c\"]]]]]], :nextjournal/viewer {:name nextjournal.clerk.viewer/html-viewer, :render-fn #viewer-fn nextjournal.clerk.render/render-html, :hash \"5drpr3yzJ1CcHNbRHnK2sVyn7YUmXB\"}}, :open-graph {:type \"article:clerk\", :title nil, :description nil}, :doc-css-class [:overflow-hidden :p-0], :blocks [{:path [], :nextjournal/value {:nextjournal/presented {:path [], :nextjournal/value \"^{:nextjournal.clerk/visibility {:code :hide :result :hide}}\\n(ns editable\\n  \\\"This is a slimmed-down version of `intro-to-modeling`. The editor view doesn't\\n  handle caching well, so I've removed the more expensive calls at the end of\\n  `intro-to-modeling`, and also changed the `pmap` call in `prepeatedly` into\\n  `map`, since we don't have `pmap` available in the browser.\\\"\\n  {:nextjournal.clerk/toc true}\\n  (:require [gen.choice-map]\\n            [gen.dynamic :as dynamic :refer [gen]]\\n            [gen.dynamic.choice-map :refer [choice-map]]\\n            [gen.clerk.callout :as callout]\\n            [gen.clerk.viewer :as viewer]\\n            [gen.distribution.kixi :as dist]\\n            [gen.generative-function :as gf]\\n            [gen.inference.importance :as importance]\\n            [gen.trace :as trace]\\n            [nextjournal.clerk :as clerk]))\\n\\n;; # Tutorial: Introduction to modeling in Gen.clj\\n\\n;; Welcome! In this tutorial, you'll get your feet wet with Gen.clj. Gen.clj is\\n;; a Clojure implementation of Gen, a multi-paradigm platform for probabilistic\\n;; modeling and inference. By \\\"multi-paradigm,\\\" we mean that Gen supports many\\n;; different approaches to modeling and inference:\\n\\n;; - Unsupervised learning and posterior inference in generative models using\\n;;   Monte Carlo, variational, EM, and stochastic gradient\\n;;   techniques.\\n\\n;; - Supervised learning of conditional inference models (e.g. supervised\\n;;   classification and regression).\\n\\n;; - Hybrid approaches including amortized inference / inference compilation,\\n;;   variational autoencoders, and semi-supervised learning.\\n\\n;; Don't worry if you haven't seen some of these approaches before. One goal of\\n;; these tutorials will be to introduce you to a subset of them, from a unified\\n;; probabilistic programming perspective.\\n\\n^{::clerk/visibility {:code :hide}}\\n(callout/alert\\n :title\\n \\\"\\\\\\\"Gen\\\\\\\" vs \\\\\\\"Gen.clj\\\\\\\"\\\"\\n :message\\n \\\"Gen.clj, the Clojure implementation of the Gen language, currently only\\n supports a subset of Gen's features. For a complete implementation see\\n [Gen.jl](https://github.com/probcomp/Gen.jl). If you would like to get involved\\n with Gen.clj's development please [contact us](mailto:contributing@zane.io).\\\")\\n\\n;; ### In this Tutorial\\n\\n;; Approaching a problem from a probabilistic perspective requires both\\n;; *modeling* and *inference*:\\n\\n;; - **Modeling**: You first need to frame the problem — and any assumptions you\\n;;   bring to the table — as a probabilistic model. A huge variety of problems\\n;;   can be viewed from a modeling & inference lens, if you set them up\\n;;   properly.  **This notebook is about how to think of problems in this light,\\n;;   and how to use Gen** **to formally specify your assumptions and the tasks\\n;;   you wish to solve.**\\n\\n;; - **Inference**: You then need to do the hard part: inference, that is,\\n;;   solving the problem. In this notebook, we'll use a particularly simple\\n;;   *generic* inference algorithm: importance sampling with the prior as our\\n;;   proposal distributions. With enough computation, the algorithm can in\\n;;   theory solve any modeling and inference problem, but in practice, for most\\n;;   problems of interest, it is too slow to achieve accurate results in a\\n;;   reasonable amount of time.  **Future tutorials introduce some of Gen's**\\n;;   **programmable inference features**, which let you tailor the inference\\n;;   algorithm for use with more complex models (Gen will still automate the\\n;;   math!).\\n\\n;; Throughout this tutorial, we will emphasize key degrees of modeling\\n;; flexibility afforded by the probabilistic programming approach, for example:\\n\\n;; - Using a stochastic branching and function abstraction to express\\n;;   uncertainty about which of multiple models is appropriate.\\n\\n;; - Representing models with an unbounded number of parameters (a 'Bayesian\\n;;   non-parametric' model) using loops and recursion.\\n\\n;; We'll also introduce a technique for validating a model and inference\\n;; algorithm by predicting new data from inferred parameters, and comparing this\\n;; data to the observed data set.\\n\\n;; However, this tutorial does not exhaustively cover all features of Gen's\\n;; modeling language. For example, Gen's modeling combinators and its static\\n;; modeling language enable improved performance, but are not covered here.\\n\\n;; ## 1. Clojure, Gen, and this Clerk notebook\\n\\n;; Gen is a library for the Clojure programming language. The library can be\\n;; required with:\\n;;\\n;; ```clojure\\n;; (require '[gen.dynamic :as dynamic :refer [gen]])\\n;; ```\\n\\n;; Gen programs typically consist of a combination of (i) probabilistic models\\n;; written in modeling languages and (ii) inference programs written in regular\\n;; Clojure code. Gen provides a built-in modeling language that is itself based\\n;; on Clojure.\\n\\n;; This tutorial uses a Clerk notebook. All forms in the notebook are regular\\n;; Clojure expressions. We will use Clerk metadata to some expressions so that\\n;; the value of the expression is not printed.\\n\\n(def a (+ 1 1))\\n\\n^{::clerk/visibility {:result :hide}}\\n(def b (+ 1 1))\\n\\n;; This notebook uses [vega-lite](https://vega.github.io/vega-lite/) for\\n;; plotting.\\n\\n;; This notebook will make use of Clojure keywords. Note that a Clojure keyword\\n;; is different from a Clojure string:\\n\\n(type :foo)\\n\\n(type \\\"foo\\\")\\n\\n;; Some expressions in this notebook will take a long time to evaluate. As such\\n;; we've wrapped those expressions in `clojure.core/delay`. You can force\\n;; evaluation of the delay and see the result by clicking on the 'force' button.\\n;; Try forcing the evaluation of the expression below now.\\n\\n^{::clerk/viewer viewer/delay ::clerk/width :wide}\\n(def delay-example\\n  (delay (viewer/sleep 5000)\\n         :done))\\n\\n;; ## 2. Writing a probabilistic model as a generative function\\n\\n;; Probabilistic models are represented in Gen as *generative functions*.\\n;; Generative functions are used to represent a variety of different types of\\n;; probabilistic computations including generative models, inference models,\\n;; custom proposal distributions, and variational approximations (see the [Gen\\n;; documentation](https://probcomp.github.io/Gen/dev/ref/gfi/) or the\\n;; [paper](https://dl.acm.org/doi/10.1145/3314221.3314642)). In this\\n;; tutorial,\\n;; we focus on implementing _generative models_. A generative model represents\\n;; a data-generating process; as such, it encodes any assumptions we have about\\n;; our data and our problem domain.\\n\\n;; The simplest way to construct a generative function is by using the built-in\\n;; modeling DSL. Generative functions written in the built-in modeling DSL are\\n;; based on Clojure function definition syntax, but use the `gen.dynamic/gen`\\n;; macro:\\n\\n;; ``` clojure\\n;; (def function-name-here\\n;;   (gen [input-arguments]\\n;;     ;; function body\\n;;     ))\\n;; ```\\n;; The function represents the data-generating process we are modeling.\\n;; Conceptually, every time we run the function, it should generate a new\\n;; \\\"synthetic dataset\\\" in line with our assumptions. Along the way, it will make\\n;; random choices; each random choice it makes can be thought of as adding\\n;; a random variable to a probabilistic model.\\n\\n;; Within the function body, most Clojure code is permitted, but random choices use\\n;; special syntax that annotates them with an _address_:\\n\\n;; ``` clojure\\n;; (dynamic/trace! addr distribution parameters)\\n;; ```\\n\\n;; A simple example of such an invocation is a normal distribution parametrized\\n;; with mean 0 and standard deviation 1:\\n\\n;; ```clojure\\n;; (require '[gen.distribution.commons-math :as dist])\\n;; ```\\n\\n(comment\\n  (def my-variable (dynamic/trace! :my-variable-address dist/normal 0 1)))\\n\\n;; Every random choice must be given an _address_, which can be an arbitrary\\n;; value—but we often use a keyword.  (`:my-variable-address` is a keyword in\\n;; the Clojure language.)  Think of the address as the name of a particular\\n;; random choice, which is distinct from the name of the variable. For example,\\n;; consider the following code:\\n\\n(comment\\n  (let [x (dynamic/trace! :initial-x dist/normal 0 1)]\\n    (if (< x 0)\\n      (+ x (dynamic/trace! :addition-to-x dist/normal 2 1))\\n      x)))\\n\\n;; This code manipulates a single variable, `x`, but may make up to two random\\n;; choices: `:initial-x` and `:addition-to-x`.\\n\\n;; Note that we can only use `dynamic/trace!` to give addresses to _random\\n;; choices_. The following will _not_ work because the code is trying to trace\\n;; the expression `sin(x)` which is an invocation of an ordinary Clojure\\n;; function, not a distribution.\\n\\n;; ```Clojure\\n;; # INVALID:\\n;; (def my-variable (dynamic/trace! :not-a-random-choice clojure.math/sin x))\\n;; ```\\n\\n;; (We will see a bit later that it is _also_ possible to use dynamic/trace! to\\n;; sample from helper _generative functions_, not just primitive distributions\\n;; like `normal`. But for now, think of `dynamic/trace!` as being for making\\n;; random choices.)\\n\\n;; ### Example: Bayesian linear regression\\n\\n;; Suppose we have a dataset of points $(x, y)$ in the plane, and we'd like to\\n;; infer a likely slope and intercept that explains their (linear) relationship.\\n;; To approach this problem from a probabilistic perspective, we first need to\\n;; develop a model. The model answers the question: how might this dataset have\\n;; come to be? It also encodes our assumptions, e.g., our assumption that our\\n;; data is explained by a linear relationship between $x$ and $y$.\\n\\n;; The generative function below represents a probabilistic model of a linear\\n;; relationship in the x-y plane. Given a set of $x$ coordinates, it randomly\\n;; chooses a line in the plane and generates corresponding $y$ coordinates so\\n;; that each $(x, y)$ is near the line. We might think of this function as\\n;; modeling house prices as a function of square footage, or the measured volume\\n;; of a gas as a function of its measured temperature.\\n\\n^{::clerk/visibility {:result :hide}}\\n(def line-model\\n  (gen [xs]\\n\\n    ;; We begin by sampling a slope and intercept for the line.  Before we have\\n    ;; seen the data, we don't know the values of these parameters, so we treat\\n    ;; them as random choices. The distributions they are drawn from represent our\\n    ;; prior beliefs about the parameters: in this case, that neither the slope\\n    ;; nor the intercept will be more than a couple points away from 0.\\n\\n    (let [slope (dynamic/trace! :slope dist/normal 0 1)\\n          intercept (dynamic/trace! :intercept dist/normal 0 2)\\n\\n          ;; We define a function to compute y for a given x.\\n\\n          y (fn [x]\\n              (+ (* slope x)\\n                 intercept))]\\n\\n      ;; Given the slope and intercept, we can sample y coordinates for each of\\n      ;; the x coordinates in our input vector.\\n\\n      (doseq [[i x] (map vector (range) xs)]\\n        (dynamic/trace! [:y i] dist/normal (y x) 0.1))\\n\\n      ;; Most of the time, we don't care about the return\\n      ;; value of a model, only the random choices it makes.\\n      ;; It can sometimems be useful to return something\\n      ;; meaningful, however; here, we return the function `y`.\\n      y)))\\n\\n;; The generative function takes as an argument a vector of x-coordinates. We\\n;; create one below:\\n\\n(def xs (range -5 6))\\n\\n;; Given this sequence, the generative function samples a random choice\\n;; representing the slope of a line from a normal distribution with mean `0` and\\n;; standard deviation `1`, and a random choice representing the intercept of a\\n;; line from a normal distribution with mean 0 and standard deviation `2`. In\\n;; Bayesian statistics terms, these distributions are the *prior distributions*\\n;; of the slope and intercept respectively. Then, the function samples values\\n;; for the y-coordinates corresponding to each of the provided x-coordinates.\\n\\n;; This generative function returns a function `y` encoding the slope\\n;; and intercept.\\n\\n;; We can run the model like we run a regular Clojure function:\\n\\n(def y (line-model xs))\\n\\n;; This gives us the return value of the model, but we may be more interested in\\n;; _the values of the random choices_ that `line_model` makes. **Crucially, each\\n;; random choice is annotated with a unique *address*.** A random choice is\\n;; assigned an address using the `(dynamic/trace! addr ...)` form. Addresses can be\\n;; any Clojure value.  In this program, there are two types of addresses used --\\n;; Clojure keywords and vectors of keywords and integers. Note that within the\\n;; `map-indexed` loop, the same line of code is executed multiple times, but\\n;; each time, the random choice it makes is given a distinct address.\\n\\n;; Although the random choices are not included in the return value, they *are*\\n;; included in the *execution trace* of the generative function. We can run the\\n;; generative function and obtain its trace using the [`\\n;; simulate`](https://probcomp.github.io/Gen/dev/ref/gfi/#Gen.simulate) method\\n;; from the Gen API:\\n;;\\n;; ```clojure\\n;; (require '[gen.generative-function :as gf])\\n;; ```\\n\\n(def trace (gf/simulate line-model [xs]))\\n\\n;; This method takes the function to be executed, and a tuple of arguments to\\n;; the function, and returns a trace and a second value that we will not be\\n;; using in this tutorial.\\n\\n;; A trace of a generative function contains various information about an\\n;; execution of the function. For example, it contains the arguments on which\\n;; the function was run, which are available with the API method\\n;; `gen.trace/args`:\\n;;\\n;; ```clojure\\n;; (require '[gen.trace :as trace])\\n;; ```\\n\\n\\n(trace/args trace)\\n\\n;; The trace also contains the value of the random choices, stored in a map from\\n;; address to value called a *choice map*. This map is available through the API\\n;; method `gen.trace/choices`:\\n\\n(trace/choices trace)\\n\\n;; We can pull out individual values from this map using `clojure.core/get`:\\n\\n(get (trace/choices trace) :slope)\\n\\n;; Or we can use either the choice map as a function:\\n\\n(let [choices (trace/choices trace)]\\n  (choices :slope))\\n\\n;; Or we can call the keyword on the choice map:\\n\\n(:slope (trace/choices trace))\\n\\n;; We can also read the value of a random choice directly from the trace,\\n;; without having to use `gen.trace/choices` first:\\n\\n(get trace :slope)\\n\\n(trace :slope)\\n\\n(:slope trace)\\n\\n;; The return value is also recorded in the trace, and is accessible with the\\n;; `trace/retval` API method:\\n\\n(trace/retval trace)\\n\\n;; In order to understand the probabilistic behavior of a generative function,\\n;; it is helpful to be able to visualize its traces. Below, we define a Clerk\\n;; viewer to render a trace of the generative function above. The rendering\\n;; shows the x-y data points and the line that is represented by the slope and\\n;; intercept choices.\\n\\n{::clerk/visibility {:result :hide}}\\n\\n(defn render-trace-spec\\n  [trace & {:keys [clip x-domain y-domain] :or {clip false}}]\\n  (let [[xs] (trace/args trace) ; Pull out the xs from the trace.\\n        y (trace/retval trace) ; Pull out the return value, useful for plotting.\\n        ys (for [i (range (count xs))]\\n             (trace [:y i]))\\n        data (mapv (fn [x y]\\n                     {:x x :y y})\\n                   xs\\n                   ys)]\\n    {:schema \\\"https://vega.github.io/schema/vega-lite/v5.json\\\"\\n     :embed/opts {:actions false}\\n     :data nil\\n     :layer [{:data {:values (for [x (range -5 5 (/ 10 1000))]\\n                               {:x x\\n                                :y (y x)})}\\n              :mark {:type \\\"line\\\" :color \\\"red\\\" :clip clip}\\n              :encoding {:x {:field :x :type \\\"quantitative\\\" :scale {:domain x-domain}}\\n                         :y {:field :y :type \\\"quantitative\\\" :scale {:domain y-domain}}}}\\n             {:data {:values data}\\n              :mark {:type \\\"circle\\\" :clip clip}\\n              :encoding {:x {:field :x :type \\\"quantitative\\\"}\\n                         :y {:field :y :type \\\"quantitative\\\"}}}]}))\\n\\n(def render-trace (comp clerk/vl render-trace-spec))\\n\\n^{::clerk/visibility {:result :show}}\\n(render-trace trace)\\n\\n;; Because a generative function is stochastic, we need to visualize many runs\\n;; in order to understand its behavior.\\n;;\\n;; The function below renders a grid of traces.\\n\\n(defn grid\\n  ([renderer traces]\\n   (grid {} renderer traces))\\n  ([{:keys [width] :or {width 4}} renderer traces]\\n   (apply clerk/col\\n          {::clerk/width :full}\\n          (map #(apply clerk/row %)\\n               (partition-all width (map renderer traces))))))\\n\\n(def traces (repeatedly 12 #(gf/simulate line-model [xs])))\\n\\n{::clerk/visibility {:result :show}}\\n\\n(grid #(render-trace % {:x-domain [-5 5]\\n                        :y-domain [-5 5]\\n                        :clip true})\\n      traces)\\n\\n;; ### 2.1 Exercise\\n\\n;; Write a generative function that uses the same address twice. Run it to see\\n;; what happens.\\n\\n;; ### 2.2 Exercise\\n\\n;; Write a model that generates a sine wave with random phase, period and\\n;; amplitude, and then generates y-coordinates from a given vector of\\n;; x-coordinates by adding noise to the value of the wave at each x-coordinate.\\n;; Use a `gamma(1, 1)` prior distribution for the period, and a `gamma(1, 1)`\\n;; prior distribution on the amplitude (see\\n;; `gen.distribution.commons-math/gamma`). Sampling from a Gamma distribution\\n;; will ensure to give us postive real values. Use a uniform distribution\\n;; between 0 and $2\\\\pi$ for the phase (see\\n;; `gen.distribution.commons-math/uniform`).\\n\\n;; The sine wave should implement:\\n\\n;; $$ y(x) = a \\\\sin(2\\\\pi \\\\frac{1}{p} x + \\\\varphi) $$\\n\\n;; where $a$ is the amplitude, $p$ is the period and $\\\\varphi$ is the phase.  In\\n;; Clojure the constant $\\\\pi$ can be expressed as `clojure.math/PI`.\\n\\n^{::clerk/visibility {:result :hide}}\\n(require '[clojure.math :as math])\\nmath/PI\\n\\n;; When calling `(trace/choices (gf/simulate sine-model [xs]))`, the following\\n;; choices should appear:\\n\\n;; - amplitude: `(trace :amplitude)`\\n;; - period: `(trace :period)`\\n;; - phase: `(trace :phase)`\\n\\n;; We have provided some starter code for the sine wave model:\\n\\n{::clerk/visibility {:result :hide}}\\n\\n(def sine-model\\n  (gen [xs]\\n\\n    ;; < your code here, for sampling a phase, period, and amplitude >\\n\\n    (let [y (fn [_x]\\n              1)] ; < Edit this function to compute y for a given x >\\n\\n      (dotimes [i (count xs)]\\n        (let [x (nth xs i)]\\n          (dynamic/trace! [:y i] dist/normal (y x) 0.1)))\\n\\n      y))) ; We return the `y` function so it can be used for plotting, below.\\n\\n(def sine-model-traces (repeatedly 12 #(gf/simulate sine-model [xs])))\\n\\n(defn render-sine-model-trace\\n  [trace]\\n  (let [[xs] (trace/args trace) ; Pull out the xs from the trace.\\n        min-x (apply min xs)\\n        max-x (apply max xs)\\n        y (trace/retval trace) ; Pull out the return value, useful for plotting.\\n        ys (for [i (range (count xs))]\\n             (get trace [:y i]))\\n        data (mapv (fn [x y]\\n                     {:x x :y y})\\n                   xs\\n                   ys)]\\n    (clerk/vl {:schema \\\"https://vega.github.io/schema/vega-lite/v5.json\\\"\\n               :embed/opts {:actions false}\\n               :layer [{:data {:values (for [x (range min-x max-x (/ (- max-x min-x)\\n                                                                     1000))]\\n                                         {:x x :y (y x)})}\\n                        :mark {:type \\\"line\\\" :color \\\"red\\\"}\\n                        :encoding {:x {:field :x :type \\\"quantitative\\\"}\\n                                   :y {:field :y :type \\\"quantitative\\\"}}}\\n                       {:data {:values data}\\n                        :mark \\\"circle\\\"\\n                        :encoding {:x {:field :x :type \\\"quantitative\\\"}\\n                                   :y {:field :y :type \\\"quantitative\\\"}}}]})))\\n\\n{::clerk/visibility {:result :show}}\\n\\n(grid render-sine-model-trace sine-model-traces)\\n\\n;; **Solution**\\n\\n^{::clerk/visibility {:code :fold :result :hide}}\\n(comment\\n  (def sine-model\\n    (gen [xs]\\n      (let [period (dynamic/trace! :period dist/gamma 1 1)\\n            amplitude (dynamic/trace! :amplitude dist/gamma 1 1)\\n            phase (dynamic/trace! :phase dist/uniform 0 (* 2 math/PI))\\n\\n            ;; Define a deteriministic sine wave with the values above.\\n            y (fn  [x]\\n                (* amplitude\\n                   (math/sin (+ (* x\\n                                   (/ (* 2 math/PI)\\n                                      period))\\n                                phase))))]\\n\\n        (dotimes [i (count xs)]\\n          (let [x (nth xs i)]\\n            (dynamic/trace! [:y i] dist/normal (y x) 0.1)))\\n\\n        y))))\\n\\n;; ## 3. Doing Posterior inference\\n\\n;; Of course, we don't really care about generating lots of pictures of lines\\n;; (or sine waves). We'd really like to begin with an actual dataset of observed\\n;; $(x, y)$ points, and infer the corresponding slope and intercept (or phase,\\n;; period, and amplitude). This task is called _posterior inference_.\\n\\n;; We now will provide a data set of y-coordinates and try to draw inferences\\n;; about the process that generated the data. We begin with the following data\\n;; set:\\n\\n(def ys [6.75003, 6.1568, 4.26414, 1.84894, 3.09686, 1.94026, 1.36411, -0.83959, -0.976, -1.93363, -2.91303])\\n\\n{::clerk/visibility {:result :hide}}\\n\\n(defn scatter-spec\\n  [xs ys & {:keys [color fill-opacity stroke-opacity title y-domain]}]\\n  (cond-> {:schema \\\"https://vega.github.io/schema/vega-lite/v5.json\\\"\\n           :embed/opts {:actions false}\\n           :data {:values (map (fn [x y]\\n                                 {:x x :y y})\\n                               xs\\n                               ys)}\\n           :mark {:type \\\"circle\\\"}\\n           :encoding {:x {:field :x\\n                          :type \\\"quantitative\\\"\\n                          :title \\\"X\\\"\\n                          :scale {:zero false}}\\n                      :y {:field :y\\n                          :type \\\"quantitative\\\"\\n                          :title \\\"Y\\\"\\n                          :axis {:titleAngle 0}\\n                          :scale {:zero false}}}}\\n    title (assoc :title title)\\n    color (assoc-in [:encoding :color] {:value color})\\n    fill-opacity (assoc-in [:mark :fillOpacity] fill-opacity)\\n    stroke-opacity (assoc-in [:mark :strokeOpacity] stroke-opacity)\\n    y-domain (assoc-in [:encoding :y :scale :domain] y-domain)))\\n\\n(def scatter (comp clerk/vl scatter-spec))\\n\\n{::clerk/visibility {:result :show}}\\n\\n(scatter xs ys :title \\\"observed data (linear)\\\")\\n\\n\\n;; We will assume that the line model was responsible for generating the data,\\n;; and infer values of the slope and intercept that explain the data.\\n\\n;; To do this, we write a simple *inference program* that takes the model we are\\n;; assuming generated our data, the data set, and the amount of computation to\\n;; perform, and returns a trace of the function that is approximately sampled\\n;; from the _posterior distribution_ on traces of the function, given the\\n;; observed data. That is, the inference program will try to find a trace that\\n;; well explains the dataset we created above. We can inspect that trace to find\\n;; estimates of the slope and intercept of a line that fits the data.\\n\\n;; Functions like `gen.inference.importance/importance-resampling` expect us to\\n;; provide a _model_ and also an _choice map_ representing our data set and\\n;; relating it to the model.  A choice map maps random choice addresses from the\\n;; model to values from our data set. Here, we want to tie model addresses like\\n;; `[:y, 4]` to data set values like `(nth ys 4)`:\\n;;\\n;; ```clojure\\n;; (require '[gen.inference.importance :as importance])\\n;; ```\\n\\n(defn do-inference\\n  [model xs ys amount-of-computation]\\n  ;; Create a choice map that maps model addresses `[:y, i]` to observed values\\n  ;; `(nth ys i)`. We leave :slope and :intercept unconstrained, because we want\\n  ;; them to be inferred.\\n  (let [observations (reduce (fn [observations [i y]]\\n                               (assoc observations [:y i] y))\\n                             (choice-map {})\\n                             (map-indexed vector ys))]\\n    (:trace (importance/resampling model [xs] observations amount-of-computation))))\\n\\n;; We can run the inference program to obtain a trace, and then visualize the result:\\n\\n(def inference-trace (do-inference line-model xs ys 100))\\n\\n{::clerk/visibility {:result :show}}\\n\\n(render-trace inference-trace)\\n\\n;; We see that `importance_resampling` found a reasonable slope and intercept to\\n;; explain the data. We can also visualize many samples in a grid:\\n\\n(grid render-trace (repeatedly 12 #(do-inference line-model xs ys 100)))\\n\\n;; We can see here that there is some uncertainty: with our limited data, we\\n;; can't be 100% sure exactly where the line is. We can get a better sense for\\n;; the variability in the posterior distribution by visualizing all the traces\\n;; in one plot, rather than in a grid. Each trace is going to have the same\\n;; observed data points, so we only plot those once, based on the values in the\\n;; first trace:\\n\\n^{::clerk/visibility {:result :hide}}\\n(defn overlay\\n  [traces]\\n  (clerk/vl {:schema \\\"https://vega.github.io/schema/vega-lite/v5.json\\\"\\n             :embed/opts {:actions false}\\n             :layer (mapv render-trace-spec traces)}))\\n\\n(overlay (repeatedly 10 #(do-inference line-model xs ys 100)))\\n\\n;; ### 3.1 Exercise\\n\\n;; The results above were obtained with `amount-of-computation` set to `100`.\\n;; Run the algorithm with this value set to `1`, `10`, and `1000`, etc.  Which\\n;; value seems like a good tradeoff between accuracy and running time? Discuss.\\n\\n;; ### 3.2 Exercise\\n\\n;; Consider the following data set.\\n\\n(def ys-sine [2.89 2.22 -0.612 -0.522 -2.65 -0.133 2.70 2.77 0.425 -2.11 -2.76])\\n\\n(scatter xs ys-sine)\\n\\n;; Write an inference program that generates traces of `sine-model` that explain\\n;; this data set. Visualize the resulting distribution of traces. Temporarily\\n;; change the prior distribution on the period to be `(gamma 1 1)`  (by changing\\n;; and re-evaluating the definition of `sine-model` from a previous exercise).\\n;; Can you explain the difference in inference results when using `(gamma 1  1)`\\n;; vs `(gamma 5 1)` prior on the period? How much computation did you need to\\n;; get good results?\\n\\n;; ## 4. Predicting new data\\n\\n;; What if we'd want to predict `ys` given `xs`?\\n\\n;; Using the API method `gen.generative-function/generate`, we can generate a\\n;; trace of a generative function in which the values of certain random choices\\n;; are constrained to given values. The constraints are a choice map that maps\\n;; the addresses of the constrained random choices to their desired values.\\n\\n;; For example:\\n\\n(def predicting-constraints (choice-map {:slope 0 :intercept 0}))\\n(def predicting-trace (:trace (gf/generate line-model [xs] predicting-constraints)))\\n\\n(def predict-opts\\n  {:x-domain [-5 5]\\n   :y-domain [-5 5]\\n   :clip true})\\n\\n(render-trace predicting-trace predict-opts)\\n\\n;; Note that the random choices corresponding to the y-coordinates are still\\n;; made randomly. We can generate more traces to verify this.\\n\\n(->> (repeatedly 4 #(:trace (gf/generate line-model [xs] predicting-constraints)))\\n     (grid #(render-trace % predict-opts)))\\n\\n;; We will use the ability to run constrained executions of a generative\\n;; function to predict the value of the y-coordinates at new x-coordinates by\\n;; running new executions of the model generative function in which the random\\n;; choices corresponding to the parameters have been constrained to their\\n;; inferred values.  We have provided a function below (`predict-new-data`) that\\n;; takes a trace, and a vector of new x-coordinates, and returns a vector of\\n;; predicted y-coordinates corresponding to the x-coordinates in `new-xs`. We\\n;; have designed this function to work with multiple models, so the set of\\n;; parameter addresses is an argument (`param-addrs`):\\n\\n(defn predict-new-data\\n  [model trace new-xs param-addrs]\\n  ;; Copy parameter values from the inferred trace (`trace`) into a fresh set of\\n  ;; constraints.\\n  (let [constraints (reduce (fn [cm param-addr]\\n                              (assoc cm param-addr (get trace param-addr)))\\n                            (choice-map {})\\n                            param-addrs)\\n\\n        ;; Run the model with new x coordinates, and with parameters\\n        ;; fixed to be the inferred values.\\n        {new-trace :trace} (gf/generate model [new-xs] constraints)]\\n\\n    ;; Pull out the y-values and return them.\\n    (mapv #(get new-trace [:y %])\\n          (range (count new-xs)))))\\n\\n;; To illustrate, we call the function above given the previous trace (which\\n;; constrained slope and intercept to be zero).\\n\\n(predict-new-data line-model predicting-trace [1.0 2.0 3.0] [:slope :intercept])\\n\\n;; The cell below defines a function that first performs inference on an\\n;; observed data set (`xs`, `ys`), and then runs `predict-new-data` to generate\\n;; predicted y-coordinates. It repeats this process `num-traces` times, and\\n;; returns a vector of the resulting y-coordinate vectors.\\n\\n(defn infer-and-predict\\n  [model xs ys new-xs param-addrs num-traces amount-of-computation]\\n  (repeatedly num-traces\\n              #(let [trace (do-inference model xs ys amount-of-computation)]\\n                 (predict-new-data model trace new-xs param-addrs))))\\n\\n;; To illustrate, we generate predictions at `[1.0 2.0 3.0]` given one\\n;; (approximate) posterior trace.\\n\\n(infer-and-predict line-model xs ys [1.0 2.0 3.0] [:slope :intercept] 1 1000)\\n\\n;; Finally, we define a cell that plots the observed data set (`xs`, `ys`) as\\n;; red dots, and the predicted data as small black dots.\\n\\n^{::clerk/visibility {:result :hide}}\\n(defn plot-predictions\\n  [xs ys new-xs pred-ys & {:keys [title]}]\\n  (let [points (fn [xs ys type order opacity]\\n                 (mapv (fn [x y]\\n                         {:x x :y y :type type :order order :opacity opacity})\\n                       xs\\n                       ys))]\\n    (clerk/vl\\n     (cond-> {:schema \\\"https://vega.github.io/schema/vega-lite/v5.json\\\"\\n              :embed/opts {:actions false}\\n              :data {:values (into (points xs ys :observed 1 1.0)\\n                                   (mapcat (fn [ys]\\n                                             (points new-xs ys :predicted 0 0.1))\\n                                           pred-ys))}\\n              :mark {:type \\\"circle\\\"}\\n              :encoding {:x {:field :x :type \\\"quantitative\\\" :title \\\"X\\\" :scale {:zero false}}\\n                         :y {:field :y :type \\\"quantitative\\\" :title \\\"Y\\\" :scale {:zero false}}\\n                         :color {:field :type :type \\\"nominal\\\" :legend {:title false}}\\n                         :order {:field :order}\\n                         :opacity {:field :opacity :type \\\"quantitative\\\" :legend false}}}\\n       title (assoc :title title)))))\\n\\n;; Recall the original dataset for the line model. The x-coordinates span the\\n;; interval `-5` to `5.`\\n\\n(scatter xs ys :title \\\"observed data\\\")\\n\\n;; We will use the inferred values of the parameters to predict y-coordinates\\n;; for x-coordinates in the interval `5` to `10` from which data was not\\n;; observed.  We will also predict new data within the interval `-5` to `5`, and\\n;; we will compare this data to the original observed data. Predicting new data\\n;; from inferred parameters, and comparing this new data to the observed data is\\n;; the core idea behind *posterior predictive checking*. This tutorial does not\\n;; intend to give a rigorous overview behind techniques for checking the quality\\n;; of a model, but intends to give high-level intuition.\\n\\n(def new-xs (vec (range -5 10 (/ 15.0 100))))\\n\\n;; We generate and plot the predicted data:\\n\\n(def pred-ys (infer-and-predict line-model xs ys new-xs [:slope :intercept] 20 1000))\\n(plot-predictions xs ys new-xs pred-ys)\\n\\n;; The results look reasonable, both within the interval of observed data and in\\n;; the extrapolated predictions on the right.\\n\\n;; Now consider the same experiment run with the following data set, which has\\n;; significantly more noise.\\n\\n(def ys-noisy [5.092 4.781 2.46815 1.23047 0.903318 1.11819 2.10808 1.09198 0.0203789 -2.05068 2.66031])\\n\\n(let [pred-ys (infer-and-predict line-model xs ys-noisy new-xs [:slope :intercept] 20 1000)]\\n  (plot-predictions xs ys-noisy new-xs pred-ys))\\n\\n;; It looks like the generated data is less noisy than the observed data in the\\n;; regime where data was observed, and it looks like the forecasted data is too\\n;; overconfident. This is a sign that our model is mis-specified. In our case,\\n;; this is because we have assumed that the noise has value `0.1`. However, the\\n;; actual noise in the data appears to be much larger. We can correct this by\\n;; making the noise a random choice as well and inferring its value along with\\n;; the other parameters.\\n\\n;; We first write a new version of the line model that samples a random choice\\n;; for the noise from a `(dist/gamma 1 1)` prior distribution.\\n\\n^{::clerk/visibility {:result :hide}}\\n(def line-model-fancy\\n  (gen [xs]\\n    (let [slope (dynamic/trace! :slope dist/normal 0 1)\\n          intercept (dynamic/trace! :intercept dist/normal 0 2)\\n          y (fn [x]\\n              (+ (* slope x)\\n                 intercept))\\n          noise (dynamic/trace! :noise dist/gamma 1 1)]\\n      (doseq [[i x] (map-indexed vector xs)]\\n        (dynamic/trace! [:y i] dist/normal (y x) noise))\\n      y)))\\n\\n;; Then, we compare the predictions using inference of the unmodified and\\n;; modified models on the `ys` data set:\\n\\n(clerk/row\\n (let [pred-ys (infer-and-predict line-model xs ys new-xs [:slope :intercept] 20 1000)]\\n   (plot-predictions xs ys new-xs pred-ys :title \\\"fixed noise\\\"))\\n (let [pred-ys (infer-and-predict line-model-fancy xs ys new-xs [:slope :intercept] 20 1000)]\\n   (plot-predictions xs ys new-xs pred-ys :title \\\"inferred noise\\\")))\\n\\n;; Notice that there is more uncertainty in the predictions made using the\\n;; modified model.\\n\\n;; We also compare the predictions using inference of the unmodified and\\n;; modified models on the `ys-noisy` data set:\\n\\n(clerk/row\\n (let [pred-ys (infer-and-predict line-model xs ys-noisy new-xs [:slope :intercept] 20 1000)]\\n   (plot-predictions xs ys-noisy new-xs pred-ys :title \\\"fixed noise\\\"))\\n (let [pred-ys (infer-and-predict line-model-fancy xs ys-noisy new-xs [:slope :intercept] 20 1000)]\\n   (plot-predictions xs ys-noisy new-xs pred-ys :title \\\"inferred noise\\\")))\\n\\n;; Notice that while the unmodified model was very overconfident, the modified\\n;; model has an appropriate level of uncertainty, while still capturing the\\n;; general negative trend.\\n\\n;; ### 4.1 Exercise\\n\\n^{::clerk/visibility {:code :hide}}\\n(callout/warning\\n \\\"This exercise requires that you have implemented `sine-model` in exercise 2.1.\\n Be sure to complete that exercise before attempting this one.\\\")\\n\\n;; Write a modified version of the sine model that makes noise into a random\\n;; choice. Compare the predicted data with the observed data using\\n;; `infer-and-predict` and `plot-predictions` for the unmodified and modified\\n;; models, and for the `ys-sine` and `ys-noisy` data sets. Discuss the results.\\n;; Experiment with the amount of inference computation used. The amount of\\n;; inference computation will need to be higher for the model with the noise as\\n;; a random choice.\\n\\n;; We have provided you with starter code:\\n\\n^{::clerk/visibility {:result :hide}}\\n(def sine-model-fancy\\n  (gen [xs]\\n    ;; < your code here >\\n    (let [y (fn [x]\\n              ;; < your code here >\\n              x)]\\n      (doseq [[i x] (map-indexed vector xs)]\\n        (dynamic/trace! [:y i] dist/normal (y x) 0.1))\\n      y)))\\n\\n;; Experiment with the vaue of `ex-4-1-computation` below.\\n\\n(def ex-4-1-computation 2)\\n\\n(let [pred-ys (infer-and-predict sine-model xs ys-sine new-xs [] 20 ex-4-1-computation)\\n      pred-ys-fancy (infer-and-predict sine-model-fancy xs ys-sine new-xs [] 20 ex-4-1-computation)]\\n  (clerk/row\\n   (plot-predictions xs ys-sine new-xs pred-ys :title [\\\"ys-sine\\\" \\\"fixed noise level\\\"])\\n   (plot-predictions xs ys-sine new-xs pred-ys-fancy :title [\\\"ys-sine\\\" \\\"inferred noise level\\\"])))\\n\\n(let [pred-ys (infer-and-predict sine-model xs ys-noisy new-xs [] 20 ex-4-1-computation)\\n      pred-ys-fancy (infer-and-predict sine-model-fancy xs ys-noisy new-xs [] 20 ex-4-1-computation)]\\n  (clerk/row\\n   (plot-predictions xs ys-noisy new-xs pred-ys :title [\\\"ys-noisy\\\" \\\"fixed noise level\\\"])\\n   (plot-predictions xs ys-noisy new-xs pred-ys-fancy :title [\\\"ys-noisy\\\" \\\"inferred noise level\\\"])))\\n\\n;; **Solution**\\n\\n^{::clerk/visibility {:code :fold :result :hide}}\\n(comment\\n  (def sine-model-fancy\\n    (gen [xs]\\n      (let [period (dynamic/trace! :period dist/gamma 5 1)\\n            amplitude (dynamic/trace! :amplitude dist/gamma 1 1)\\n            phase (dynamic/trace! :phase dist/uniform 0 (* 2 math/PI))\\n            noise (dynamic/trace! :noise dist/gamma 1 1)\\n            y (fn [x]\\n                (* amplitude\\n                   (math/sin (+ (* x\\n                                   (/ (* 2 math/PI)\\n                                      period))\\n                                phase))))]\\n        (doseq [[i x] (map-indexed vector xs)]\\n          (dynamic/trace! [:y i] dist/normal (y x) noise)))\\n      y)))\\n\\n;; ## 5. Calling other generative functions\\n\\n;; In addition to making random choices, generative functions can invoke other\\n;; generative functions. To illustrate this, we will write a probabilistic model\\n;; that combines the line model and the sine model. This model is able to\\n;; explain data using either model, and which model is chosen will depend on the\\n;; data. This is called *model selection*.\\n\\n;; A generative function can invoke another generative function in ~~three~~ two\\n;; ways:\\n\\n;; 1. **(NOT RECOMMENDED)** using regular Clojure function call syntax: `(f x)`\\n;; 2. using `dynamic/trace!` with an address for the call: `(dynamic/trace! :addr f x)`\\n;; 3. using `dynamic/splice!`, which does not require an address: `(dynamic/splice! f x)`\\n\\n;; When invoking using regular function call syntax, the random choices made by\\n;; the callee function are not traced at all, and Gen cannot reason about them\\n;; during inference. When invoking using `dynamic/splice!` the random choices of\\n;; the callee function are imported directly into the caller's trace. So, for\\n;; example, if `f` makes a choice called `:f-choice`, then the caller's trace\\n;; will have a choice called `:f-choice` too. Note that a downside of this is\\n;; that if `f` is called _twice_ by the same caller, then the two choices called\\n;; `:f-choice` will clash, leading to an error. In this case, it is best to\\n;; provide an address (`(dynamic/trace! addr f)`): `f`'s random choices will\\n;; be placed under the _key_ `addr`.\\n\\n(def foo\\n  (gen []\\n    (dynamic/trace! :y dist/normal 0 1)))\\n\\n(def bar\\n  (gen []\\n    (dynamic/trace! :x dist/bernoulli 0.5)\\n    ;; Call `foo` with `dynamic/splice!`. Its choices (`:y`) will appear directly\\n    ;; within the trace of `bar`.\\n    (dynamic/splice! foo)))\\n\\n(def bar-with-key\\n  (gen []\\n    (dynamic/trace! :x dist/bernoulli 0.5)\\n    ;; Call `foo` with the address `:z`.  The internal choice `:y` of `foo` will\\n    ;; appear in our trace at the hierarchical address `[:z :y]`.\\n    (dynamic/trace! :z foo)))\\n\\n;; We first show the addresses sampled by `bar`:\\n\\n(trace/choices (gf/simulate bar []))\\n\\n;; And the addresses sampled by `bar-with-key`:\\n\\n(def bar-with-key-trace (gf/simulate bar-with-key []))\\n(trace/choices bar-with-key-trace)\\n\\n;; Using `dynamic/trace!` instead of `dynamic/splice!` can help avoid address\\n;; collisions for complex models.\\n\\n;; Hierarchical traces are represented using nested choice maps\\n;; (`gen.dynamic.choice-map/ChoiceMap`). Hierarchical addresses can be accessed\\n;; using `clojure.core` functions like `clojure.core/get-in`.\\n\\n(get-in bar-with-key-trace [:z :y])\\n\\n;; Now, we write a generative function that combines the line and sine models.\\n;; It makes a Bernoulli random choice (e.g. a coin flip that returns true or\\n;; false) that determines which of the two models will generate the data.\\n\\n(def combined-model\\n  (gen [xs]\\n    (if (dynamic/trace! :is-line dist/bernoulli 0.5)\\n      ;; Call `line-model-fancy` on xs, and import its random choices directly\\n      ;; into our trace.\\n      (dynamic/splice! line-model-fancy xs)\\n      ;; Call `sine-model-fancy` on xs, and import its random choices directly\\n      ;; into our trace.\\n      (dynamic/splice! sine-model-fancy xs))))\\n\\n;; We visualize some traces, and see that sometimes it samples linear data and\\n;; other times sinusoidal data.\\n\\n(let [traces (repeatedly 12 #(gf/simulate combined-model [xs]))]\\n  (grid render-trace traces))\\n\\n;; We run inference using this combined model on the `ys` data set and the\\n;; `ys-sine` data set.\\n\\n#_\\n(let [amount-of-computation 10000\\n      ys-traces (repeatedly 10 #(do-inference combined-model xs ys amount-of-computation))\\n      ys-sine-traces (repeatedly 10 #(do-inference combined-model xs ys-sine amount-of-computation))]\\n  (clerk/row\\n   (overlay ys-traces)\\n   (overlay ys-sine-traces)))\\n\\n;; The results should show that the line model was inferred for the `ys` data\\n;; set, and the sine wave model was inferred for the `ys-sine` data set.\\n\\n;; ### 5.1 Exercise\\n\\n;; Construct a data set for which it is ambiguous whether the line or sine wave\\n;; model is best. Visualize the inferred traces using `render-combined` to\\n;; illustrate the ambiguity. Write a program that takes the data set and returns\\n;; an estimate of the posterior probability that the data was generated by the\\n;; sine wave model, and run it on your data set.\\n\\n^{::clerk/visibility {:code :hide}}\\n(callout/hint\\n \\\"To estimate the posterior probability that the data was generated by the sine\\n  wave model, run the inference program many times to compute a large number of\\n  traces, and then compute the fraction of those traces in which `:is-line` is\\n  false.\\\")\\n\", :nextjournal/visibility {:code :hide, :result :show}, :nextjournal/viewer {:render-fn #viewer-fn nextjournal.clerk.render.editor/view, :hash \"5drezFtVFKXa6Et6NFPfyHcdbGzLuB\"}, :nextjournal/render-opts {:id \"intro-to-modeling.edit/anon-expr-5drUqpSr7X7t2dzswawoRKL2eaksUN-result\"}}, :nextjournal/blob-id \"5dt2gKcsL9zyTdVtcjCaF2nxG1SrXu\"}, :nextjournal/render-opts {:id \"intro-to-modeling.edit/anon-expr-5drUqpSr7X7t2dzswawoRKL2eaksUN-result\"}, :nextjournal/visibility {:code :hide, :result :show}, :nextjournal/viewer {:name nextjournal.clerk.viewer/result-viewer, :render-fn #viewer-fn nextjournal.clerk.render/render-result, :hash \"5dtGVHesd2XCTLFYF3aY4kJvkrX1x1\"}}]}, :nextjournal/viewer {:name nextjournal.clerk.viewer/notebook-viewer, :render-fn #viewer-fn nextjournal.clerk.render/render-notebook, :hash \"5duAFDxE4sCnRX71Wo6zeCpC9C3djE\"}}}, :path->url {\"examples/introduction.clj\" \"examples/introduction.html\", \"examples/intro_to_modeling.clj\" \"\", \"examples/intro_to_modeling/edit.clj\" \"examples/intro_to_modeling/edit.html\"}, :current-path \"examples/intro_to_modeling/edit.clj\", :resource->url {\"/js/viewer.js\" \"https://cas.clerk.garden/tree/8VxCcd2nQqrhPLVttyyM5Rnv8qMYcjeSEjgJnhZTvCgVhmgsNWWeusxmVkfX9ajrXmFqQEdVmtdHSoCdHLG2XTsXXB/.clerk/shadow-cljs/main.js\"}, :index \"examples/intro_to_modeling.clj\"}".replaceAll('nextjournal.clerk.view/escape-closing-script-tag', 'script')
viewer.init(viewer.read_string(state))
</script></body></html>